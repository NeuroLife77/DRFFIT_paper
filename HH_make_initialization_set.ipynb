{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.HH_model.utils import get_targets\n",
    "from os import makedirs\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from lib.HH_model.parameters_info import parameters_initial0, parameters_range_bounds, parameters_lower_bound, parameter_names\n",
    "from lib.drffit.uniform_sampler import uniform_around_sampler as uniform_sampler\n",
    "from lib.HH_model.simulator import HH_simulator\n",
    "import joblib\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "from lib.utils import *\n",
    "from copy import deepcopy as dcp\n",
    "device = 'cpu'#torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mpl.rcParams['font.size'] = 12\n",
    "V_test, I_test = HH_simulator(np.array([parameters_initial0]), length = 0.01, dt = 0.01)\n",
    "parameters_upper_bound = parameters_lower_bound+parameters_range_bounds\n",
    "midpoint = parameters_lower_bound+ parameters_range_bounds/2\n",
    "upper_bound = dcp(parameters_upper_bound)\n",
    "lower_bound = dcp(parameters_lower_bound)\n",
    "theta_min = lower_bound#upper_bound#parameters_lower_bound\n",
    "theta_range = upper_bound - lower_bound#parameters_range_bounds\n",
    "range_bounds = upper_bound - lower_bound\n",
    "print('Parameters:\\n')\n",
    "for i, pn in enumerate(parameter_names):\n",
    "    print('\\t',i,'\\t',pn,':    \\t',parameters_lower_bound[i],'   \\t',parameters_upper_bound[i])\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_njobs = 10\n",
    "# Info settings\n",
    "targets_file = 'trial_1'\n",
    "glob_data_path = '../Data/HH/initialization/'\n",
    "\n",
    "save_sample_data = True\n",
    "\n",
    "# Simulation settings\n",
    "dt = 0.01\n",
    "length = 0.05\n",
    "cutoff = 10000 # 100ms (resolution of 0.01ms)\n",
    "chunk_size, num_chunks = 25, 400\n",
    "sample_distribution = 'cube'\n",
    "# Sampler settings\n",
    "search_width = 1.0\n",
    "point = midpoint\n",
    "number_of_simulations = chunk_size * num_chunks\n",
    "sampler_fn = uniform_sampler(theta_min, theta_range = theta_range, sample_distribution=sample_distribution)\n",
    "sampler_fn.set_state(point = point, width=search_width)\n",
    "file_name = f'{sample_distribution}{number_of_simulations}_{count}'\n",
    "# To keep track of runtime\n",
    "runtime = datetime.now()-datetime.now()\n",
    "st_time = datetime.now()\n",
    "st_time_string = st_time.strftime('%D, %H:%M:%S')\n",
    "print(f'Start time: {st_time_string}')\n",
    "\n",
    "# Produce samples and simulate\n",
    "parameters_samples = [sampler_fn.sample((chunk_size,)) for _ in range(num_chunks)]\n",
    "all_samples = torch.cat(parameters_samples, dim = 0)\n",
    "print(len(parameters_samples))\n",
    "\n",
    "n_jobs = num_chunks\n",
    "if num_chunks > max_njobs:\n",
    "    n_jobs = max_njobs\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41c3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(2,6,i+1)\n",
    "    plt.violinplot(ensure_numpy(all_samples)[:,i])\n",
    "    plt.ylim([lower_bound[i],upper_bound[i]])\n",
    "    plt.title(f\"{parameter_names[i]}\")\n",
    "plt.suptitle('Distribution of parameter values over the samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67bf031",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_seed=np.random.randint(0,2**16)\n",
    "results = joblib.Parallel(n_jobs=n_jobs, verbose = 1)(joblib.delayed(HH_simulator)(\n",
    "                                                                        parameters,\n",
    "                                                                        length = length,\n",
    "                                                                        dt=dt,\n",
    "                                                                        noise_seed=noise_seed\n",
    "                                ) for i, parameters in enumerate(parameters_samples))\n",
    "# Group the simulations\n",
    "time_series_V, I = zip(*results)\n",
    "\n",
    "# Define the log_info dict\n",
    "simulated_samples = torch.cat(time_series_V, dim = 0)\n",
    "parameters_samples_good = torch.cat(parameters_samples, dim = 0)\n",
    "log_info = {}\n",
    "log_info['dt'] = dt\n",
    "log_info['length'] = length\n",
    "log_info['chunk_size'] = chunk_size\n",
    "log_info['num_chunks'] = num_chunks\n",
    "log_info['total_simulations'] = chunk_size*num_chunks\n",
    "log_info['valid_simulations'] = simulated_samples.shape[0]\n",
    "log_info['noise_seed'] = noise_seed\n",
    "log_info['search_width'] = search_width\n",
    "log_info['point'] = point\n",
    "if save_sample_data:\n",
    "    log_info['data'] = {'x':simulated_samples,'theta':parameters_samples_good, 'stats':None }\n",
    "log_info['message'] = 'Searching around known point with narrow range for \"easy\" test'\n",
    "log_info['date'] = datetime.now().strftime('%D, %H:%M:%S')\n",
    "runtime = datetime.now()-st_time\n",
    "f_time_string = datetime.now().strftime('%D, %H:%M:%S')\n",
    "runtime_string = str(runtime)\n",
    "print(f'Finish time: {f_time_string}, Runtime: {runtime_string}')\n",
    "print(f\"Simulations shape: {simulated_samples.shape[0]}, {simulated_samples.shape[1]}\")\n",
    "print(f\"Parameters shape: {parameters_samples_good.shape[0]}, {parameters_samples_good.shape[1]}\\n\")\n",
    "print(\"Log info:\")\n",
    "data_info(log_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc5e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss_fn_batch(target, candidates, batch = None, device = 'cuda'):\n",
    "    target = target.view(1,-1)\n",
    "    loss_f = mse\n",
    "    if batch is None:\n",
    "        loss = loss_f(candidates, target)\n",
    "    else:\n",
    "        target = target.to(device)\n",
    "        loss = []\n",
    "        num_candidates = candidates.shape[0]\n",
    "        batch_size = num_candidates//batch\n",
    "        for i in range(0, num_candidates, batch_size):\n",
    "            batch_candidates = candidates[i:i+batch_size].to(device)\n",
    "            loss.append(loss_f(batch_candidates, target))\n",
    "        loss = torch.cat(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba428344",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_x, target_theta = get_targets(file = targets_file)\n",
    "print(f'Target shape: {target_x.shape},\\t Candidates shape: {simulated_samples.shape}')\n",
    "target_x = target_x[:,:simulated_samples.shape[1]]\n",
    "train_x = simulated_samples\n",
    "train_theta = parameters_samples_good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "all_errs = []\n",
    "initial_points = []\n",
    "loss_fn = 'mse'\n",
    "sorted_target = []\n",
    "target_x = target_x\n",
    "train_x = train_x#.to('cpu')\n",
    "for i in tqdm(range(target_x.shape[0])):\n",
    "    error = mse_loss_fn_batch(target_x[i].view(1,-1),train_x, batch = 1)\n",
    "    err_index = torch.argmin(error).cpu()\n",
    "    sorted_target.append({\n",
    "            'theta':train_theta[err_index].view(1,-1),\n",
    "            'x': train_x[err_index].cpu().view(1,-1),\n",
    "            'error':error[err_index].cpu().view(1,-1),\n",
    "            'target':target_x[i].cpu().view(1,-1),\n",
    "            'target_theta':target_theta[i].view(1,-1),\n",
    "            'real_index':torch.tensor(i).view(1,-1)\n",
    "    })\n",
    "    all_errs.append(error[err_index].data.item())\n",
    "all_errs = torch.tensor(all_errs)\n",
    "sorted_errors = torch.argsort(all_errs, descending = True)\n",
    "sorted_target_info = []\n",
    "for i in sorted_errors:\n",
    "    sorted_target_info.append(sorted_target[i])\n",
    "\n",
    "target_log = {\n",
    "    'original': {'x': target_x.cpu(),'theta':target_theta},\n",
    "    'sorted':{\n",
    "        'data':{'source':glob_data_path, 'x': train_x.cpu(), 'theta':train_theta},\n",
    "        'loss_fn': loss_fn,\n",
    "        'indices':sorted_errors,\n",
    "    }\n",
    "}\n",
    "\n",
    "target_log['original']['fits'] = {}\n",
    "target_log['original']['fits']['theta'] = torch.cat([sorted_target[i]['theta'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['original']['fits']['x'] = torch.cat([sorted_target[i]['x'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['original']['fits']['error'] = torch.cat([sorted_target[i]['error'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['original']['fits']['target'] = torch.cat([sorted_target[i]['target'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['original']['fits']['target_theta'] = torch.cat([sorted_target[i]['target_theta'] for i in range(target_x.shape[0])], dim = 0)\n",
    "\n",
    "\n",
    "target_log['sorted']['worst_info_all'] = {}\n",
    "target_log['sorted']['worst_info_all']['theta'] = torch.cat([sorted_target_info[i]['theta'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['sorted']['worst_info_all']['x'] = torch.cat([sorted_target_info[i]['x'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['sorted']['worst_info_all']['error'] = torch.cat([sorted_target_info[i]['error'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['sorted']['worst_info_all']['target'] = torch.cat([sorted_target_info[i]['target'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['sorted']['worst_info_all']['target_theta'] = torch.cat([sorted_target_info[i]['target_theta'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['sorted']['worst_info_all']['real_index'] = torch.cat([sorted_target_info[i]['real_index'] for i in range(target_x.shape[0])], dim = 0)\n",
    "target_log['original']['reorder'] = torch.argsort(target_log['sorted']['worst_info_all']['real_index'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbe1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_log['sorted']['worst_info_all']['x'].shape)   \n",
    "print(target_log['sorted']['data']['x'].shape)   \n",
    "print()\n",
    "print(torch.sqrt(target_log['sorted']['worst_info_all']['error'].mean()))\n",
    "print(torch.sqrt(target_log['sorted']['worst_info_all']['error'][:100].mean()))\n",
    "print(torch.sqrt(target_log['sorted']['worst_info_all']['error'][:100].min()))\n",
    "print()\n",
    "print(torch.sqrt(target_log['sorted']['worst_info_all']['error'].max()))\n",
    "print(torch.sqrt(target_log['sorted']['worst_info_all']['error'].min()))\n",
    "print()\n",
    "print((target_log['sorted']['worst_info_all']['target'][target_log['original']['reorder']] == target_log['original']['x']).all())\n",
    "print(glob_data_path+'mse_loss/',file_name)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11981ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "makedirs(glob_data_path, exist_ok = True)\n",
    "save_log(target_log, glob_data_path, f'{file_name}_fits', enforce_replace = False)\n",
    "count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "16b3cb373ab163b43349ea32823e4187dc37f8a5f4a04aa5ed18ab49bf23b1de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
