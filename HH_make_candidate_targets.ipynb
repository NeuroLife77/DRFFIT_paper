{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from lib.HH_model.parameters_info import parameters_initial0, parameters_range_bounds, parameters_lower_bound, parameters_upper_bound, parameter_names\n",
    "from lib.drffit.uniform_sampler import uniform_around_sampler as uniform_sampler\n",
    "from lib.HH_model.simulator import HH_simulator\n",
    "import joblib\n",
    "import pickle as pkl\n",
    "from datetime import datetime\n",
    "from lib.utils import *\n",
    "from copy import deepcopy as dcp\n",
    "set_mpl()\n",
    "device = 'cpu'\n",
    "mpl.rcParams['font.size'] = 12\n",
    "V_test, I_test = HH_simulator(np.array([parameters_initial0]), length = 0.01, dt = 0.01)\n",
    "midpoint = parameters_lower_bound+ parameters_range_bounds/2\n",
    "theta_min = parameters_lower_bound\n",
    "theta_range = parameters_range_bounds\n",
    "range_bounds = theta_range\n",
    "print('Parameters:\\n')\n",
    "for i, pn in enumerate(parameter_names):\n",
    "    print('\\t',i,'\\t',pn,':    \\t',parameters_lower_bound[i],'   \\t',parameters_upper_bound[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate samples from a sample space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_njobs = 10\n",
    "# Info settings\n",
    "data_path = '../Data/HH/targets/'\n",
    "file_name = 'trial_1'\n",
    "save_sample_data = True\n",
    "\n",
    "# Simulation settings\n",
    "dt = 0.01\n",
    "length = 0.05\n",
    "cutoff = 10000 # 100ms (resolution of 0.01ms)\n",
    "chunk_size, num_chunks = 50, 500\n",
    "\n",
    "# Sampler settings\n",
    "search_width = 1.0\n",
    "point = midpoint\n",
    "sampler_fn = uniform_sampler(theta_min, theta_range = theta_range, sample_distribution='cube')\n",
    "sampler_fn.set_state(point = point, width=search_width)\n",
    "# To keep track of runtime\n",
    "runtime = datetime.now()-datetime.now()\n",
    "st_time = datetime.now()\n",
    "st_time_string = st_time.strftime('%D, %H:%M:%S')\n",
    "print(f'Start time: {st_time_string}')\n",
    "\n",
    "# Produce samples and simulate\n",
    "parameters_samples = [sampler_fn.sample((chunk_size,)) for _ in range(num_chunks)]\n",
    "all_samples = torch.cat(parameters_samples,dim = 0)\n",
    "print(len(parameters_samples))\n",
    "\n",
    "n_jobs = num_chunks\n",
    "if num_chunks > max_njobs:\n",
    "    n_jobs = max_njobs\n",
    "print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,6))\n",
    "for i in range(12):\n",
    "    ax = plt.subplot(2,6,i+1)\n",
    "    plt.violinplot(ensure_numpy(all_samples)[:,i])\n",
    "    plt.ylim([lower_bound[i],upper_bound[i]])\n",
    "    plt.title(f\"{parameter_names[i]}\")\n",
    "plt.suptitle('Distribution of parameter values over the samples')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_seed=np.random.randint(0,2**16)\n",
    "results = joblib.Parallel(n_jobs=n_jobs, verbose = 1)(joblib.delayed(HH_simulator)(\n",
    "                                                                        parameters,\n",
    "                                                                        length = length,\n",
    "                                                                        dt=dt,\n",
    "                                                                        noise_seed=noise_seed\n",
    "                                ) for i, parameters in enumerate(parameters_samples))\n",
    "# Group the simulations\n",
    "time_series_V, I = zip(*results)\n",
    "\n",
    "# Define the log_info dict\n",
    "simulated_samples = torch.cat(time_series_V, dim = 0)\n",
    "parameters_samples_good = torch.cat(parameters_samples, dim = 0)\n",
    "makedirs(data_path, exist_ok = True)\n",
    "\n",
    "log_info = {}\n",
    "log_info['dt'] = dt\n",
    "log_info['length'] = length\n",
    "log_info['chunk_size'] = chunk_size\n",
    "log_info['num_chunks'] = num_chunks\n",
    "log_info['total_simulations'] = chunk_size*num_chunks\n",
    "log_info['valid_simulations'] = simulated_samples.shape[0]\n",
    "log_info['noise_seed'] = noise_seed\n",
    "log_info['search_width'] = search_width\n",
    "log_info['point'] = point\n",
    "if save_sample_data:\n",
    "    log_info['data'] = {'x':simulated_samples,'theta':parameters_samples_good, 'stats':None }\n",
    "log_info['message'] = 'Searching around known point with narrow range for \"easy\" test'\n",
    "log_info['date'] = datetime.now().strftime('%D, %H:%M:%S')\n",
    "runtime = datetime.now()-st_time\n",
    "f_time_string = datetime.now().strftime('%D, %H:%M:%S')\n",
    "runtime_string = str(runtime)\n",
    "print(f'Finish time: {f_time_string}, Runtime: {runtime_string}')\n",
    "print(f\"Simulations shape: {simulated_samples.shape[0]}, {simulated_samples.shape[1]}\")\n",
    "print(f\"Parameters shape: {parameters_samples_good.shape[0]}, {parameters_samples_good.shape[1]}\\n\")\n",
    "print(\"Log info:\")\n",
    "data_info(log_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify good targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "n_clusters=25\n",
    "kmeans = KMeans(n_clusters=n_clusters, tol = 1e-8).fit(simulated_samples)\n",
    "sorted_cluster_id = np.flip(np.argsort(kmeans.cluster_centers_.max(1)))\n",
    "cluster_ids = kmeans.predict(simulated_samples)\n",
    "clustered_x = [[] for i in range(n_clusters)]\n",
    "clustered_theta = [[] for i in range(n_clusters)]\n",
    "for i, ids in enumerate(cluster_ids):\n",
    "    clustered_x[ids].append(simulated_samples[i].unsqueeze(0)) \n",
    "    clustered_theta[ids].append(parameters_samples_good[i].unsqueeze(0)) \n",
    "for i, cluster in enumerate(clustered_x):\n",
    "    try:\n",
    "        clustered_x[i] = torch.cat(cluster, dim = 0)\n",
    "    except:\n",
    "        pass\n",
    "for i, cluster in enumerate(clustered_theta):\n",
    "    try:\n",
    "        clustered_theta[i] = torch.cat(cluster, dim = 0)\n",
    "    except:\n",
    "        pass\n",
    "centers = kmeans.cluster_centers_[sorted_cluster_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clustered_x[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_col = 5\n",
    "f = plt.figure(figsize=(30,3.5*(len(centers)//num_col + 1)))\n",
    "t = np.arange(int(55/dt))*dt\n",
    "# Timeseries V\n",
    "for i, cluster in enumerate(clustered_x):\n",
    "    ax = plt.subplot(len(clustered_x)//num_col +1,num_col,1+i)\n",
    "    ax.plot(t,cluster[0, :int(55/dt)], label = f\"Item 0\")\n",
    "    try:\n",
    "        ax.plot(t,cluster[1, :int(55/dt)], label = f\"Item 1\")\n",
    "    except:\n",
    "        pass\n",
    "    plt.xlabel('Time [ms]')\n",
    "    plt.ylabel('Voltage [mV]')\n",
    "    plt.legend()\n",
    "    plt.title(f'Cluster {i} with {cluster.shape[0]} items')\n",
    "plt.suptitle('Time series of cluster centers\\n')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "thetas = []\n",
    "for i, cluster in enumerate(clustered_x):\n",
    "    dist_from_center = correlation_loss_fn(ensure_torch(kmeans.cluster_centers_[i]).view(1,-1), cluster)\n",
    "    sorted_by_dist = torch.argsort(dist_from_center)\n",
    "    targets.append(cluster[sorted_by_dist[:10]])\n",
    "    targets.append(cluster[sorted_by_dist[-10:]])\n",
    "    thetas.append(clustered_theta[i][sorted_by_dist[:10]])\n",
    "    thetas.append(clustered_theta[i][sorted_by_dist[-10:]])\n",
    "targets = torch.cat(targets, dim = 0)\n",
    "thetas = torch.cat(thetas, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets.shape)\n",
    "print(thetas.shape)\n",
    "log_info['kmeans'] = kmeans\n",
    "log_info['clusters'] = {'x':clustered_x, 'theta':clustered_theta}\n",
    "log_info['targets'] = {'x': targets, 'theta':thetas}\n",
    "log_info['message'] = 'Generating targets from extensive whole space search and selecting the 10 closest and 10 furthest of the 25 clusters of the simulations'\n",
    "save_log(log_info, data_path, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_only = {}\n",
    "targets_only['targets'] = {'x': targets, 'theta':thetas}\n",
    "targets_only['source'] = {'path': data_path, 'file': file_name}\n",
    "save_log(targets_only, data_path, file_name+'_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "f = plt.figure(figsize=(20,10))\n",
    "# Timeseries V\n",
    "ax = plt.subplot(1,1,1)\n",
    "for i in range(start, start + 5):\n",
    "    ax.plot(t,simulated_samples[i, :int(100/dt)], label = f\"Parameter set {i}\")\n",
    "plt.xlabel('Time [ms]')\n",
    "plt.ylabel('Voltage')\n",
    "plt.title('Time series V')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e5ed47acc9f465cc49c81a47bd4fc7fc53b021c2e7eea4784274e8c56d9104f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
